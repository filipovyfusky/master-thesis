\newpage
\section{Image annotation}

In supervised learning, one needs to manually create the training data consisting of inputs and corresponding targets (called Ground Truths in segmentation). There's a variety of annotation tools available on the internet, both under commercial and free licenses. 

\subsubsection{Labelbox}

Labelbox in a paid online annotation tool. The best feature of Labelbox \cite{labelbox} is that it allows sharing the datasets with other users and therefore speed up the labeling significantly. Labelbox offers free access to the full version to students. When the labeling is finished, one exports the image/label pairs to a \textit{.JSON} file. This file contains links to the annotated images that are stored online and it's necessary to download them separately (Labelbox is still in development, this is valid by the time of publishing the thesis). To automate this process, one can call the function \textit{download()} from the \textit{utilities.py} script (Attachment XY). 

%\section{Caffe Commands}

%The documentation for Caffe is not one of the best and sometimes it might be quite %tricky to find reasonable answers. Therefore, this section will give a brief %summary of the most important terms and parameters in Caffe library.

\section{Setting up SegNet}

Caffe implementation of ANN typically consists of four \textit{.prototxt} files: \textit{train.prototxt}, \textit{solver.prototxt}, \textit{test.prototxt} and \textit{inference.prototxt}. The \textit{train}, \textit{test} and \textit{inference} files are almost identical except for a few differences in the very first/last layers of the network. The \textit{train} file is used together with the \textit{solver} file to train the network: the network architecture is determined by the \textit{train} file and the parameters for optimization reside in the \textit{solver} file. The \textit{test} file is used by Caffe when one needs to test the network periodically during training on a validation dataset. The \textit{inference} file is used for running the trained network.

The files used in this section are available at \cite{filip_github}

\subsection{Solver settings}

The \textit{solver} file contains the optimization parameters. The description of the parameters can be found in the original Caffe documentation \cite{caffe}. The example of the parameters used can be found in the snippet below. 

\begin{lstlisting}[caption={Contents of \textit{solver.prototxt}},captionpos=b]
// Training file
net: "/path/to/train.prototxt"	
// Caffe GPU version
solver_mode: GPU
// Solver type		
type: "AdaDelta"
// Initial learning rate, changes according to lr_policy		
base_lr: 0.061		
// Determines how the learning rate changes during training
lr_policy: "fixed"	
// Show loss and accuracy every 'display' iterations
display: 130
// Max number of iteration. One iteration = a pass of one mini batch			
max_iter: 3000	
// Regularization technique called Weight decay		
weight_decay: 0.0005
// Saves the weights after 'snapshot' iterations
snapshot: 1000000		
snapshot_prefix: "/path/to/snap" 
\end{lstlisting}

\subsection{Training}

\subsubsection{Input layer and input pre-processing}

The \textit{train} file begins with the \textit{DenseImageData} layer. This layer specifies the size of the mini batch. The value is limited by the amount of memory the GPU offers. When a larger size of the mini batch is needed, one solution that Caffe offers is to specify the \textit{iter\_size} parameter in the \textit{solver} file. The total mini batch size in Caffe is always a result of $iter\_size \cdot batch\_size$. By default, the value of \textit{iter\_size} is set to 1.

The \textit{shuffle} parameter in the \textit{DenseImageData} layer determines whether the training dataset is shuffled after each epoch. This is usually desirable as it helps the optimization algorithm by adding more stochasticity to the computation. The \textit{mirror} parameter applies random mirrors to the input data and hence augments the dataset. If one needs to apply more complex data augmentation techniques, it's necessary to perform them separately and feed the \textit{DenseImageData} layer with already processed images.

\begin{lstlisting}[caption={Input layer in \textit{train.prototxt}},captionpos=b]
// The first layer in the network
name: "segnet_train"
layer {
name: "data"
type: "DenseImageData"
top: "data"
top: "label"
dense_image_data_param {
	source: "/path/to/train_image_paths.txt"
	batch_size: 4   			    			
	shuffle: true
	mirror: true	
	}
# Per-channel mean
transform_param {
	mean_value: 129		#B component
	mean_value: 126		#G
	mean_value: 126		#R
	}
}
\end{lstlisting} 

Images and labels are loaded as \textit{.jpg} and \textit{.png} files directly from the hard drive (there are more methods that Caffe offers). The path to the \textit{image\_paths.txt} file that contains the image/label paths in the following format

$$
\text{\textit{/path/to/image.jpg /path/to/label.png}}
$$

\noindent is entered as the \textit{source} parameter of the \textit{DenseImageData} layer. This file is generated using the function \textit{make\_txt()} from \textit{utilities.py}. The script will also make separate directories for training, testing and validation datasets by calling \textit{make\_dirs()}.

The method used for mean subtraction was the per-channel mean. The function per\_channel\_mean in utilities.py calculates the mean values for R, G and B components of the images in the training set. These three numbers are then placed into the \textit{DenseImageData} layer in BGR order (see Snippet XY).

\subsubsection{Output dimensions}

In the original version, SegNet segments 11 classes. This corresponds to the pixel values in the \textit{.png} label files starting from zero: for instance, the segmentation mask for the class number 1 has a pixel value of 0 in the label file, etc. However, the goal of this thesis is to set the network to segment only two classes - \textit{path, background}. To change the size of the output classifier, it is necessary to change the output dimensions of the last \textit{conv} layer:

\begin{lstlisting}[caption={Setting number of outputs in \textit{train.prototxt}},captionpos=b]

// The last conv layer in the network
layer {
	bottom: "conv1_2_D"
	top: "conv1_1_D"
	name: "conv1_1_D"
	type: "Convolution"
	.
	.
	.
	convolution_param {
		.
		.
		.
		num_output: 2		// Set this to the number of classes
		pad: 1
		kernel_size: 3
	}
}
\end{lstlisting}

\newpage
\subsubsection{Softmax classifier}

\enquote{When there is a large variation in the number of pixels in each class in the training set (e.g road, sky and building pixels dominate the dataset) then there is a need to weight the loss differently based on the true class. This is called class balancing. The authors of SegNet use median frequency balancing where the weight assigned to a class in the loss function is the ratio of the median of class frequencies computed on the entire training set divided by the class frequency. This implies that larger classes in the training set have a weight smaller than 1 and the weights of the smallest classes are the highest.} \cite{segnet} When no re-weighting is applied, we talk about natural frequency balancing.

\begin{lstlisting}[caption={Output layers of \textit{train.prototxt}},captionpos=b]
// The Softmax classifier with cross-entropy loss
layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "loss"
	softmax_param {engine: CAFFE}
	loss_param: {
		weight_by_label_freqs: false	     
	}
}
// The last layer of the network
layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "accuracy"
	top: "per_class_accuracy"
}
\end{lstlisting}

%% Snippet XY, the last two layers of the train network

SegNet uses the cross-entropy loss as the loss function for training the network. In Caffe, median frequency balancing is available via the \textit{weight\_by\_label\_freqs} parameter of the \textit{SoftmaxWithLoss} layer. Since the dataset used has only two classes whose occurrences can be considered as balanced, this option is set to \textit{false}. 

\subsubsection{Training initialization}

\noindent Training the network from scratch is initiated by entering these commands:

\begin{lstlisting}[language=bash]
# Navigate to the caffe-segnet folder
$ cd /path/to/caffe-segnet/build/tools/
# Initiate training from scratch or
$ ./caffe train -solver /path/to/segnet_solver.prototxt
# or resume training from a solver checkpoint (snapshot)
$ ./caffe train -solver /path/to/segnet_solver.prototxt -snapshot /path/to/snapshot_iter_XY.solverstate
\end{lstlisting}

The encoder and decoder weights are initialized using MSRA method by default. Another scenario is when it's desired to use transfer learning (Caffe library has a Model Zoo where people share their network weights). In this case, Caffe needs a path to the \textit{.caffemodel} file of the pre-trained network. The corresponding command would be:

\begin{lstlisting}[language=bash]
$ ./caffe train -solver /path/to/solver.prototxt -weights /path/to/pre_trained_weights.caffemodel
\end{lstlisting}

There are multiple scenarios of tuning the pre-trained model when using transfer learning. For instance, one can experiment with the learning rate of the pre-trained weights: they can either stay unchanged (zero learning rate) or the learning rate applied to them is lower than the global value used in other layers. In encoder-decoder architecture, one usually applies transfer learning only to the encoder network as its only purpose is to extract general features from the image. The corresponding setting in the \textit{train} file are the lr\_mult parameters by which the learning rate for the layer is multiplied. An example of setting a Caffe layer to stay unchanged can be found in the snippet below.

\begin{lstlisting}[caption={Setting up \textit{train.prototxt} for transfer learning},captionpos=b]
layer {
	bottom: "data"
	top: "conv1_1"
	name: "conv1_1"
	type: "Convolution"
	# Learning rate factor - weights
	param {
		lr_mult: 0			# Remains unchanged during training
		decay_mult: 0		# Remains unchanged during training
	}
	# Learning rate factor - thresholds
	param {
		lr_mult: 0			# Remains unchanged during training
		decay_mult: 0		# Remains unchanged during training
	}
	.
	.
	.
}
\end{lstlisting}

% [https://arxiv.org/pdf/1411.4734.pdf]

\newpage
\subsection{Inference}

In this phase, the network is ready to be deployed. From this point, it's very convenient to use pycaffe for running the model, feeding it with input data and calculating the segmentation accuracy. To run the segmentation, several preparation steps must be taken first.

\subsubsection{Calculating statistics for batch normalisation}
The batch normalisation layers in SegNet shift the input feature maps according to their mean and variance statistics for each mini batch during training. At inference time we must use the statistics for the entire dataset and obtain the final \textit{.caffemodel} for the inference phase. \cite{segnet_get_started} We do this by calling the \textit{compute\_bn\_statistics.py} which is meant to be run from the command line and needs to get command-line parameters. In PyCharm, we need to switch to Virtual Environment (venv) by opening Terminal and call:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 original_compute_bn_statistics.py /path/to/train.prototxt /path/to/snap_iter_XY.caffemodel /path/to/inference_folder
\end{lstlisting}

The network architecture for the inference is now in the \textit{inference} file and is the same as in the \textit{train} file, apart from the input and output layers and the settings of the Batch Normalisation layers. The snippet below shows how the output changes: the loss function is no longer computed and the only output we care about are the Softmax probabilities. The \textit{DenseImageData} layer is also skipped, because the data will be provided via pycaffe. Part of this is switching all Batch Normalisation layers to the INFERENCE mode.

The script takes the desired \textit{.caffemodel} file specified in \textit{snap\_iter\_XY.caffemodel}, calculates new $ \gamma, \beta $ parameters for the Batch Normalisation layers and saves everything to \textit{final\_weights.caffemodel}. The new \textit{.caffemodel} file is now stored in the specified \textit{inference\_folder}.

\begin{lstlisting}[caption={Replacing input layer type in \textit{inference.prototxt}},captionpos=b]
// Inference, input layer
name: "segnet_inference"
input: "data"
input_dim: 1	# Always 1 for SegNet
input_dim: 3
input_dim: 360
input_dim: 480
\end{lstlisting}

\subsubsection{Running the Segmentation}

The script \textit{segnet\_inference.py} is used for running the segmentation. One must provide the network the images either by specifying a path to a video file or by specifying a sequence of image names to look for in the image folder (this is a standard OpenCV [odkaz na to jakej to ma mit format] convention). In each step of the algorithm, we must subtract the per-channel mean from the input image being processed. This is part of the script and one only needs to provide the BGR values used at train time.

Once an appropriate test set of images is ready, the segmentation is started by calling:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 segnet_inference.py /path/to/inference.prototxt /path/to/final_weights.caffemodel /path/to/videofile.avi 
\end{lstlisting}

\subsection{Testing}

The \textit{test} file is used only for calculating the loss of the validation dataset. It's very similar to the \textit{train} file: it has \textit{DenseImageData} layer with the path to the validation dataset, \textit{mirror} and \textit{shuffle} parameters set to false, \textit{batch\_size} to 1 and the \textit{SoftmaxWithLoss} followed by \textit{Accuracy} layers as the output. The subtraction of the per-channel mean is still present and the values are computed from the training dataset and are the same as in the training phase. 

For the testing, it is necessary to use the \textit{.caffemodel} file generated by \textit{compute\_bn\_statistics.py} to ensure proper function of the Batch Normalisation layers, which must be in the INFERENCE mode and differ from the settings of the \textit{train} file.

\begin{lstlisting}[caption={Setting up the input layer of \textit{test.prototxt}},captionpos=b]
name: "segnet_test"
layer {
	name: "data"
	type: "DenseImageData"
	top: "data"
	top: "label"
	dense_image_data_param {
		source: "/media/phil/SegNet/data/custom/val_linux.txt"	
		batch_size: 1		# Always 1 for SegNet
	}
	# BGR order
	transform_param {
		mean_value: 129
		mean_value: 126
		mean_value: 126 
	}  
	
\end{lstlisting}

Testing is executed similarly as training using the command line:

\begin{lstlisting}[language=bash]
# Navigate to the caffe-segnet folder
$ cd /path/to/caffe-segnet/build/tools/
# Initiate testing
$ ./caffe train -model /path/to/segnet_test.prototxt -weights /path/to/final_weights.caffemodel
\end{lstlisting}

\newpage
\subsection{Bayesian SegNet}

Since Bayesian SegNet differs from SegNet only in terms of added dropout layers and a different method of performing the inference, the above-mentioned procedures for setting the solver and training are applicable in the same way. Therefore, one can start the training by using the commands from the previous section and only replace the paths of the \textit{train} and \textit{solver} files. 

The input layer in the \textit{inference} file has one major difference: unlike in SegNet, the first \textit{input\_dim} parameter at the top of the \textit{inference} file represents the number of MCDO samples and can be adjusted. At inference time, the script passes the same image \textit{input\_dim} times and simply averages the output the network gives. For this reason, the dropout layers that are by default inactive when Caffe is performing inference (TEST, in Caffe terminology) must be set to active in this case. The corresponding parameter in the dropout layer is \textit{sample\_weights\_test: true}. 

The Batch Normalisation layers are set to INFERENCE mode. The final \textit{.caffemodel} is obtained the same way as in SegNet by calling \textit{compute\_bn\_statistics.py}. Here, unlike at inference time, the network's output is computed using weight averaging technique instead of MCDO.

\begin{lstlisting}[caption={Setting MCDO in \textit{inference.prototxt}},captionpos=b]
layer {
	bottom: "conv1_1"
	top: "conv1_1"
	name: "conv1_1_bn"
	type: "BN"
	bn_param {
		bn_mode: INFERENCE			# Inference mode of BN
		.
		.
		.
	}
}
.
.
.
layer {
	name: "encdrop5"
	type: "Dropout"
	bottom: "pool5"
	top: "pool5"
	dropout_param {
		dropout_ratio: 0.5
		sample_weights_test: true	# For Monte Carlo Dropout
	}
}
\end{lstlisting}

\newpage
The setting of the \textit{test} file remains the same as in SegNet: input is provided by the \textit{DenseImageData} layer, \textit{batch\_size} is set to 1 and the Batch Normalisation layers are in INFERENCE mode. The dropout layers can also be set as active here. This \textit{test} file still serves only for checking the validation loss.

The inference is initiated by calling:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 bayesian_segnet_inference.py /path/to/inference.prototxt /path/to/final_weights.caffemodel /path/to/videofile.avi 
\end{lstlisting}

Here the scripts also visualizes the statistics of MCDO sampling: the uncertainty and variance of the output segmentation.

\subsection{SegNet Basic and Bayesian SegNet Basic}

These shallow versions of SegNet and BayesianSegNet are used in the same way as their full versions above. The same procedures apply to SegNet+SegNet Basic and Bayesian SegNet+Bayesian SegNet Basic.

\newpage
\section{Optimization of Hyperparameters}

Hyperparameters are parameters that are set before the training begins and do not change during the training. The choice of hyperparameters is a task for itself and requires a sufficient amount of tries and errors. There are some general recipes (mostly empirical) one can follow for finding the right parameters. The goal of this is to ensure that the network reaches an optimal value of the loss function. \cite{stanford-github}

\subsubsection{Cross-validation Strategy}

This strategy is also referred to as early stopping. The idea is that one observes both training and validation loss during training. When these losses go apart, the network tends to overfit to the training data. This is a crucial step when finding optimal hyperparameters and always needs to be checked. \cite{stanford-github}

\subsubsection{Optimizer}

Every training of a neural network starts with the choice of optimizer. As the most recent research suggest, Adam is the default choice for training CNN. If the CNN is built from scratch, it is advisable to start from the simplest SGD optimizer and observe the values of the loss function to detect potential problems in the architecture or code. \cite{stanford-L7}

\subsubsection{Learning Rate}

The parameter that has the biggest effect on training is the learning rate: it is the first parameter to begin with. It's recommended to start a coarse search first while observing the loss for both training and validation datasets for a few initial epochs. Then, after the training is done, choose a thinner interval of optimal learning rates and perform finer search. \cite{stanford-L6}

As the learning rate has a multiplicative effect on the gradient accumulation during mini-batch training, it's logical to pick the values from logarithmic space. \cite{stanford-L6}

\subsubsection{Regularisation}

When building a network from scratch, one starts with a simple SGD algorithm with no regularisation involved to ensure that the loss values are reasonable. Once it is ensured that there are no errors in the code and the network trains with SGD, regularisation is turned on. Then it's usually set to a very small value, typically of the order $ 10^{-4} $ \cite{stanford-L6}.



