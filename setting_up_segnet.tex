\newpage
\section{Image annotation}

In supervised learning, one needs to manually create the training data consisting of inputs and corresponding targets (called ground truths in segmentation). There's a variety of annotation tools available on the internet, both under commercial and free licenses. 

\subsubsection{Labelbox}

Labelbox \cite{labelbox} is a paid online annotation tool. The best feature of Labelbox is that it allows sharing the datasets with other users and therefore speeding up the labeling significantly. Labelbox offers free access to students to the full version. When the labeling is finished, one exports the image/label pairs to a \textit{.JSON} file. This file contains links to the annotated images that are stored online and it is necessary to download them separately (Labelbox is still in development, this is valid at the time of publishing). To automate this process, one can call the \textit{download()} function from \textit{utilities.py} which is available in \cite{filip_github}. \\

The final train, validation and test datasets used contain 2600 + 90 + 179 images from an outdoor environment. The location where the images were taken is the same in all cases. However, the scenes differ in their weather conditions, daytime, type of path, etc. The corresponding \textit{.JSON} files are available at \cite{filip_github}.

%\section{Caffe Commands}

%The documentation for Caffe is not one of the best and sometimes it might be quite %tricky to find reasonable answers. Therefore, this section will give a brief %summary of the most important terms and parameters in Caffe library.

\section{Setting up SegNet}

Caffe implementation of ANN typically consists of four \textit{.prototxt} files: \textit{train.prototxt}, \textit{solver.prototxt}, \textit{test.prototxt} and \textit{inference.prototxt}. The \textit{train}, \textit{test} and \textit{inference} files are almost identical except for a few differences in the very first/last layers of the network. The \textit{train} file is used together with the \textit{solver} file to train the network. The network architecture is determined by the \textit{train} file and the parameters for optimization reside in the \textit{solver} file. The \textit{test} file is used by Caffe when one needs to test the network periodically during training on a validation dataset. \cite{caffe} The \textit{inference} file is used for running the trained network. The files used in this section are available at \cite{filip_github}

\subsection{Solver settings}

The \textit{solver} file contains the optimization parameters. The description of the parameters can be found in the original Caffe documentation \cite{caffe}. An example of the parameters used can be found in the snippet below. 

\begin{lstlisting}[caption={Contents of \textit{solver.prototxt} \cite{filip_github}},captionpos=b]
// Training file
net: "/path/to/train.prototxt"	
// Caffe GPU version
solver_mode: GPU
// Solver type		
type: "AdaDelta"
// Initial learning rate, changes according to lr_policy		
base_lr: 0.061		
// Determines how the learning rate changes during training
lr_policy: "fixed"	
// Show loss and accuracy every 'display' iterations
display: 130
// Max number of iteration. One iteration = a pass of one mini batch			
max_iter: 3000	
// Weight decay factor		
weight_decay: 0.0005
// Saves the weights after 'snapshot' iterations
snapshot: 1000000		
snapshot_prefix: "/path/to/snap" 
\end{lstlisting}

\subsection{Training}

\subsubsection{Input layer and input pre-processing}

The \textit{train} file begins with the \textit{DenseImageData} layer. This layer specifies the size of the mini-batch. The value is limited by the amount of memory that the GPU offers. When a larger size of the mini batch is needed, Caffe can specify the \textit{iter\_size} parameter in the \textit{solver} file. The total mini-batch size in Caffe is always a result of $iter\_size \cdot batch\_size$. By default, the value of \textit{iter\_size} is set to 1. \cite{caffe}

The \textit{shuffle} parameter in the \textit{DenseImageData} layer determines whether the training dataset is shuffled after each epoch. This is usually desirable as it helps the optimization algorithm by adding more stochasticity to the computation. The \textit{mirror} parameter applies random mirrors to the input data and hence augments the dataset. If one needs to apply more complex data augmentation techniques, it is necessary to perform them separately and feed the \textit{DenseImageData} layer with already processed images. \cite{caffe}

\begin{lstlisting}[caption={Input layer in \textit{train.prototxt} \cite{filip_github}},captionpos=b]
name: "segnet_train"
layer {
name: "data"
type: "DenseImageData"
top: "data"
top: "label"
dense_image_data_param {
	source: "/path/to/train_image_paths.txt"
	batch_size: 4   			    			
	shuffle: true
	mirror: true	
	}
// Per-channel mean
transform_param {
	mean_value: 129		// B component
	mean_value: 126		// G
	mean_value: 126		// R
	}
}
\end{lstlisting} 

Images and labels are loaded as \textit{.jpg} and \textit{.png} files directly from the hard drive (there are more methods that Caffe offers, see \cite{caffe}). The path to the \textit{image\_paths.txt} file that contains the image/label paths in the following format

$$
\text{\textit{/path/to/image.jpg /path/to/label.png}}
$$

\noindent is entered as the \textit{source} parameter of the \textit{DenseImageData} layer. This file is generated using the \textit{make\_txt()} function from \textit{utilities.py}. The script will also make separate directories for training, testing and validation datasets by calling \textit{make\_dirs()}.

The method used for the mean subtraction was the per-channel mean. The \textit{per\_channel\_mean} function in \textit{utilities.py} calculates the mean values for R, G and B components of the images in the training set. These three numbers are then placed into the \textit{DenseImageData} layer in BGR order.

\subsubsection{Output dimensions}

In the original version, SegNet has 11 segmentation classes. This corresponds to the pixel values in the \textit{.png} label files starting from zero. For instance, the segmentation mask for the class number 1 has a pixel value of 0 in the label file, etc. However, the goal of this thesis is to set the network to segment only two classes - \textit{path, background}. To change the size of the output classifier, it is necessary to change the output dimensions of the last \textit{conv} layer:

\begin{lstlisting}[caption={Setting number of outputs in \textit{train.prototxt} \cite{filip_github}},captionpos=b]

// The last conv layer in the network
layer {
	bottom: "conv1_2_D"
	top: "conv1_1_D"
	name: "conv1_1_D"
	type: "Convolution"
	.
	.
	.
	convolution_param {
		.
		.
		.
		num_output: 2		// Set this to the number of classes
		pad: 1
		kernel_size: 3
	}
}
\end{lstlisting}

\newpage
\subsubsection{Softmax classifier}

\enquote{\textit{When there is large variation in the number of
	pixels in each class in the training set (e.g road, sky and building
	pixels dominate the CamVid dataset) then there is a need to weight
	the loss differently based on the true class. This is termed class
	balancing. We use median frequency balancing [13] where the
	weight assigned to a class in the loss function is the ratio of the
	median of class frequencies computed on the entire training set
	divided by the class frequency. This implies that larger classes in
	the training set have a weight smaller than 1 and the weights
	of the smallest classes are the highest. We also experimented
	with training the different variants without class balancing or
	equivalently using natural frequency balancing.}} \cite{segnet}

\begin{lstlisting}[caption={Output layers of \textit{train.prototxt} \cite{filip_github}},captionpos=b]
// The softmax classifier with cross-entropy loss
layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "loss"
	softmax_param {engine: CAFFE}
	loss_param: {
		weight_by_label_freqs: false	     
	}
}
layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "accuracy"
	top: "per_class_accuracy"
}
\end{lstlisting}

%% Snippet XY, the last two layers of the train network

SegNet uses the cross-entropy loss as the loss function for training the network. In Caffe, median frequency balancing is available via the \textit{weight\_by\_label\_freqs} parameter of the \textit{SoftmaxWithLoss} layer. Since the dataset used has only two classes whose occurrences can be considered balanced, this option is set to \textit{false}. 

\subsubsection{Training initialization}

\noindent Training the network from scratch is initiated by entering these commands:

\begin{lstlisting}[language=bash]
# Navigate to the caffe-segnet folder
$ cd /path/to/caffe-segnet/build/tools/
# Initiate training from scratch
$ ./caffe train -solver /path/to/segnet_solver.prototxt
# or resume training from a solver checkpoint (snapshot)
$ ./caffe train -solver /path/to/segnet_solver.prototxt -snapshot /path/to/snapshot_iter_XY.solverstate
\end{lstlisting}

The encoder and decoder weights are initialized using the MSRA method by default. Another scenario is when we want to use transfer learning (see Caffe Model Zoo in \cite{caffe} where people share their weights and networks). In this case, Caffe needs a path to the \textit{.caffemodel} file of the pre-trained network. The corresponding command would be:

\begin{lstlisting}[language=bash]
$ ./caffe train -solver /path/to/solver.prototxt -weights /path/to/pre_trained_weights.caffemodel
\end{lstlisting}

There are multiple ways of tuning the pre-trained model when using transfer learning. For instance, one can experiment with the learning rate of the pre-trained weights: they can either stay unchanged (zero learning rate) or the learning rate applied to them is lower than the global value used in other layers. \cite{stanford-github} In encoder-decoder architecture, one usually applies transfer learning only to the encoder network as it has no other purpose than extracting general features from the image. The corresponding setting in the \textit{train} file is the set of \textit{lr\_mult} parameters by which the learning rate for the layer is multiplied. An example of setting a Caffe layer where that layer stays unchanged can be found in the snippet below.

\begin{lstlisting}[caption={Setting up \textit{train.prototxt} for transfer learning \cite{filip_github}},captionpos=b]
layer {
	bottom: "data"
	top: "conv1_1"
	name: "conv1_1"
	type: "Convolution"
	// Learning rate factor - weights
	param {
		lr_mult: 0			// Zero value corresponds to freezing this parameter
		decay_mult: 0		// Zero value corresponds to freezing this parameter
	}
	// Learning rate factor - thresholds
	param {
		lr_mult: 0			// Zero value corresponds to freezing this parameter
		decay_mult: 0		// Zero originally, remains unchanged
	}
	.
	.
	.
}
\end{lstlisting}

% [https://arxiv.org/pdf/1411.4734.pdf]

\newpage
\subsection{Inference}

The network is ready to be deployed in this phase. At this point, it is very convenient to use pycaffe for running the model by feeding it with input data and calculating the segmentation accuracy. To run the segmentation, several preparation steps must be taken first.

\subsubsection{Calculating statistics for batch normalisation}
The batch normalisation layers in SegNet shift the input feature maps according to their mean and variance statistics for each mini- batch during training \cite{mehlig}. At inference time, we must use the statistics for the entire dataset and obtain the final \textit{.caffemodel} for the inference phase. \cite{segnet_get_started} We do this by calling \textit{compute\_bn\_statistics.py} which is meant to be run from the command line and needs to get command-line parameters. In PyCharm, we need to switch to Virtual Environment (venv) by opening Terminal and call:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 original_compute_bn_statistics.py /path/to/train.prototxt /path/to/snap_iter_XY.caffemodel /path/to/inference_folder
\end{lstlisting}

The network architecture for the inference is now in the \textit{inference} file and the same is in the \textit{train} file apart from the input and output layers and the settings of the batch normalisation layers. The snippet below shows the changes of the output: the loss function is no longer computed and the only output we care about is the set of softmax probabilities. The \textit{DenseImageData} layer is also skipped, because the data will be provided via pycaffe. Part of this is switching all batch normalisation layers to the INFERENCE mode. \cite{issue}

The script takes the desired \textit{.caffemodel} file specified in \textit{snap\_iter\_XY.caffemodel}, calculates new $ \gamma, \beta $ parameters for the batch normalisation layers and saves everything to \textit{final\_weights.caffemodel}. The new \textit{.caffemodel} file is now stored in the specified \textit{inference\_folder}. \cite{issue}

\begin{lstlisting}[caption={Replacing input layer type in \textit{inference.prototxt} \cite{filip_github}},captionpos=b]
// Inference, input layer
name: "segnet_inference"
input: "data"
input_dim: 1	// Always 1 for SegNet
input_dim: 3
input_dim: 360
input_dim: 480
\end{lstlisting}

\subsubsection{Running the segmentation}

The script \textit{segnet\_inference.py} is used for running the segmentation. One must provide the network with images either by specifying a path to a video file or by specifying a sequence of image names to look for in the image folder (this is a standard OpenCV convention). In each step of the algorithm, we must subtract the per-channel mean from the input image that is being processed. This is part of the script and one only needs to provide the BGR values used at train time.

Once an appropriate test set of images is ready, the segmentation is started by calling:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 segnet_inference.py /path/to/inference.prototxt /path/to/final_weights.caffemodel /path/to/videofile.avi 
\end{lstlisting}

\subsection{Testing}

The \textit{test} file is used only for calculating the loss of the validation dataset. It is very similar to the \textit{train} file: it has a \textit{DenseImageData} layer with a path to the validation dataset, \textit{mirror} and \textit{shuffle} parameters set to false, \textit{batch\_size} to 1 and the \textit{SoftmaxWithLoss} followed by \textit{Accuracy} layers as the output. The subtraction of the per-channel mean is still present and the values computed from the training dataset are the same as in the training phase. 

For testing, it is necessary to use the \textit{.caffemodel} file generated by \textit{compute\_bn\_statistics.py} to ensure the proper function of the batch normalisation layers, which must be in the INFERENCE mode and must differ from the settings of the \textit{train} file.

\begin{lstlisting}[caption={Setting up the input layer of \textit{test.prototxt} \cite{filip_github}},captionpos=b]
name: "segnet_test"
layer {
	name: "data"
	type: "DenseImageData"
	top: "data"
	top: "label"
	dense_image_data_param {
		source: "/media/phil/SegNet/data/custom/val_linux.txt"	
		batch_size: 1		// Always 1 for SegNet
	}
	// Per-channel mean, BGR
	transform_param {
		mean_value: 129
		mean_value: 126
		mean_value: 126 
	}  
	
\end{lstlisting}

Testing is executed similarly as training using the command line:

\begin{lstlisting}[language=bash]
# Navigate to the caffe-segnet folder
$ cd /path/to/caffe-segnet/build/tools/
# Initiate testing
$ ./caffe train -model /path/to/segnet_test.prototxt -weights /path/to/final_weights.caffemodel
\end{lstlisting}

\newpage
\subsection{Bayesian SegNet}

Since Bayesian SegNet differs from SegNet only in terms of added dropout layers and a different method of performing the inference the above-mentioned procedures for setting the solver and training are also applicable. Therefore, one can start the training by using commands from the previous section. One must also not forget to replace the paths of the \textit{train} and \textit{solver} files. 

The input layer in the \textit{inference} file has one major difference: unlike in SegNet, the first \textit{input\_dim} parameter at the top of the \textit{inference} file represents the number of MCDO samples and can be adjusted. At inference time, the script passes the same image \textit{input\_dim} times and simply averages the output of the network. For this reason, the dropout layers that are inactive by default when Caffe is performing inference (TEST, in Caffe terminology) must be set to active in this case. The corresponding parameter in the dropout layer is \textit{sample\_weights\_test: true}. 

The batch normalisation layers are set to INFERENCE mode. The final \textit{.caffemodel} is obtained the same way as in SegNet by calling \textit{compute\_bn\_statistics.py}. Here, unlike during inference time, the network's output is computed using the weight averaging technique instead of MCDO.

\begin{lstlisting}[caption={Setting MCDO in \textit{inference.prototxt} \cite{filip_github}},captionpos=b]
layer {
	bottom: "conv1_1"
	top: "conv1_1"
	name: "conv1_1_bn"
	type: "BN"
	bn_param {
		bn_mode: INFERENCE			// Inference mode of this batch norm. layer
		.
		.
		.
	}
}
.
.
.
layer {
	name: "encdrop5"
	type: "Dropout"
	bottom: "pool5"
	top: "pool5"
	dropout_param {
		dropout_ratio: 0.5
		sample_weights_test: true	// For Monte Carlo Dropout
	}
}
\end{lstlisting}

\newpage
The setting of the \textit{test} file remains the same as in SegNet: input is provided by the \textit{DenseImageData} layer, \textit{batch\_size} is set to 1 and the batch normalisation layers are in INFERENCE mode. The dropout layers can also be set to active here. This \textit{test} file still only serves for checking the validation loss.

The inference is initiated by calling:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 bayesian_segnet_inference.py /path/to/inference.prototxt /path/to/final_weights.caffemodel /path/to/videofile.avi 
\end{lstlisting}

Here the scripts also visualizes the statistics of MCDO sampling: the variance of the output segmentation computed from all MCDO samples.

\subsection{SegNet Basic and Bayesian SegNet Basic}

SegNet Basic and Bayesian SegNet Basic are networks provided by the SegNet authors and are similar to their full versions but have fewer layers (see Attachment 1). These shallow versions are used in the same way as their parent architectures. Therefore, the same training and inference procedures apply to SegNet+SegNet Basic and Bayesian SegNet+Bayesian SegNet Basic.

\newpage
\section{Optimization of hyperparameters}

Hyperparameters are parameters that are set before the training begins and do not change during the training. The choice of hyperparameters is a task in its own right and requires a sufficient amount of trial and error. There are some general approaches (mostly empirical) one can follow to find the right parameters. The goal is to ensure that the network reaches an optimal value of the loss function. \cite{stanford-github}

\subsubsection{Optimizer}

Every training of a neural network starts with the choice of an optimizer. As the most recent research suggests, Adam is the default choice for training CNNs. If the CNN is built from scratch, it is advisable to start from the simplest SGD optimizer and observe the values of the loss function to detect potential problems in the architecture or the code. \cite{stanford-L7}

\subsubsection{Learning rate}

The parameter that has the biggest effect on training is the learning rate: it is the first parameter one should set. It is recommended to start a coarse search first while observing the loss for both training and validation datasets for a few initial epochs. Then, after the training is done, choose a thinner interval of optimal learning rates and perform a finer search. \cite{stanford-L6}

As the learning rate has a multiplicative effect on the gradient accumulation during mini-batch training, it is logical to pick the values from the logarithmic space. \cite{stanford-L6}

\subsubsection{Cross-validation strategy}

This strategy is also referred to as early stopping. The idea is that one observes both training and validation loss during training. When these losses go apart, the network tends to overfit to the training data. This is a crucial step when finding optimal hyperparameters and it must always be checked. \cite{stanford-github}

\subsubsection{Regularisation}

When building a network from scratch, one starts with a simple SGD algorithm with no regularisation involved to ensure that the loss values are reasonable. After we check for errors in the code and after the network trains with SGD, regularisation is turned on. It is usually set to a very small value, typically of the order $ 10^{-4} $ \cite{stanford-L6}.



