\section{Image Annotation}

In supervised learning, one needs to manually create the training data consisting of inputs and corresponding targets (in segmentation, ground truths). There's a variety of annotation tools available on the internet, both under commercial and free licenses. 

\subsubsection{Labelbox}

Labelbox in a paid online annotation tool. The best feature of Labelbox is that it allows sharing the datasets with other users and therefore speed up the labeling significantly. Labelbox offers free access to the full version to students. When the labeling is finished, one needs to export the image/label pairs to a .JSON file. This file contains links to the annotated images that are stored online and it's necessary to download them separately (Labelbox is still in development, this is valid by the time of publishing the thesis). To automate this process, one can call the function \textit{download()} from the \textit{utilities.py} file (Attachment XY). 

%\section{Caffe Commands}

%The documentation for Caffe is not one of the best and sometimes it might be quite %tricky to find reasonable answers. Therefore, this section will give a brief %summary of the most important terms and parameters in Caffe library.

\section{Setting up SegNet}

Caffe implementation of a neural network typically consists of four \textit{.prototxt} files: \textit{train.prototxt}, \textit{solver.prototxt}, \textit{test.prototxt} and \textit{inference.prototxt}. The train, test and inference files are almost identical except for a few differences in the very first/last layers. The train file is used together with the solver file to train the network: the network architecture is determined by the train file and the parameters for optimization reside in the solver file. The test file is used by Caffe when one needs to test the network periodically during training on a validation dataset.  

The network files used in this section are available at [filip github].

\subsection{Solver Settings}

The solver file contains the optimization parameters. The detailed description of the parameters can be found in the original Caffe documentation on GitHub [odkaz na dokumentaci]. The description of the parameters used can be found in the snippet below. 

\begin{lstlisting}
// Training file
net: "/path/to/train.prototxt"	
// Caffe GPU version
solver_mode: GPU
// Solver type		
type: "AdaDelta"
// Initial learning rate, changes according to lr_policy		
base_lr: 0.061		
// Determines how the learning rate changes during training
lr_policy: "fixed"	
// Show loss and accuracy every 'display' iterations
display: 130
// Max number of iteration. One iteration = a pass of one mini-batch			
max_iter: 3000	
// Regularization technique called Weight decay		
weight_decay: 0.0005
// Saves the weights after 'snapshot' iterations
snapshot: 1000000		
snapshot_prefix: "/path/to/snap" 

// Testing parameters
test_initialization: false	
test_iter: 1
test_interval: 100000000
\end{lstlisting}

\subsection{Training}

\subsubsection{Input Layer and Input pre-processing}

The train file begins with the DenseImageData. Images and labels are loaded as \textit{.jpg} and \textit{.png} files directly from the hard drive (there are more methods Caffe offers). The path to the \textit{image\_paths.txt} file containg the image/label paths is entered as the \textit{source} parameter of the \textit{DenseImageData}. This layer also specifies the size of the mini batch. The value is limited by the amount of memory GPU offers. When a larger size of the mini batch is needed, one solution Caffe offers is to specify the \textit{iter\_size} parameter in the Solver file. The total mini batch size in Caffe is always a result of $iter\_size \cdot batch\_size$. By default, the value of \textit{iter\_size} is set to 1.

The \textit{shuffle} parameter in the DenseImageData layer determines whether the training dataset is shuffled after each epoch. This is usually desirable as it helps the optimization algorithm by bringing another stochasticity into the computation. The \textit{mirror} parameter applies random mirrors to the input data and hence augments the dataset. If one needs to apply more complex data augmentation techniques, it's necessary to perform them separately and feed the DenseImageData layer with already processed images.

\begin{lstlisting}
// The first layer in the network
name: "bayesian_segnet_train"
layer {
name: "data"
type: "DenseImageData"
top: "data"
top: "label"
dense_image_data_param {
	source: "/SegNet_navganti/data/custom/train_linux.txt"
	batch_size: 4   			    			
	shuffle: true
	mirror: true	
	}
# Per-channel mean
transform_param {
	mean_value: 129		#B component
	mean_value: 126		#G
	mean_value: 126		#R
	}
}
\end{lstlisting} 

The training images and their ground truths are stored as \textit{.jpg} and \textit{.png} files. The corresponding pairs are denoted as rows in the \textit{image\_paths.txt} file in the format 

$$
\text{\textit{/path/to/image.jpg /path/to/label.png}}
$$

This file is generated using the function \textit{make\_txt()} from \textit{utilities.py}. The script will also make separate directories for training, testing and validation datasets by calling \textit{make\_dirs()}.

The method used for mean subtraction was the per-channel mean method. The function per\_channel\_mean in utilities.py calculates the mean values for R, G and B components from the training set. These three numbers are then placed into the DenseImageData layer in BGR order (see Snippet XY).

\subsubsection{Output Dimensions}

In the original version, SegNet segments 11 classes. This corresponds to the pixel values in the .png label files starting from zero: for instance, segmentation mask for class number 1 has a pixel value 0 in the label file, etc. However, the goal of this thesis is to set the network to segment only two classes - \textit{path, background}. To change the size of the output classifier, it is necessary to change the output dimension of the last layer:

\begin{lstlisting}

// The last conv layer in the network
layer {
	bottom: "conv1_2_D"
	top: "conv1_1_D"
	name: "conv1_1_D"
	type: "Convolution"
	.
	.
	.
	convolution_param {
		.
		.
		.
		num_output: 2		// Set this to the number of classes
		pad: 1
		kernel_size: 3
	}
}
\end{lstlisting}

\subsubsection{Softmax Classifier}

When there is large variation in the number of pixels in each class in the training set (e.g road, sky and building pixels dominate the dataset) then there is a need to weight the loss differently based on the true class. This is called class balancing. The authors of SegNet use median frequency balancing [odkaz] where the weight assigned to a class in the loss function is the ratio of the median of class frequencies computed on the entire training set divided by the class frequency. This implies that larger classes in the training set have a weight smaller than 1 and the weights of the smallest classes are the highest. When no re-weighting is applied, we talk about natural frequency balancing. [doslovna citace??? segnet paper]

\begin{lstlisting}
// The Softmax classifier with cross-entropy loss
layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "loss"
	softmax_param {engine: CAFFE}
	loss_param: {
		weight_by_label_freqs: false	     
	}
}
// The last layer of the network
layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "accuracy"
	top: "per_class_accuracy"
}
\end{lstlisting}

%% Snippet XY, the last two layers of the train network

SegNet uses the cross-entropy loss as the loss function for training the network. In Caffe, median frequency balancing is available via the 'weight\_by\_label\_freqs' parameter in the \textit{SoftmaxWithLoss} layer. Since the dataset used has only two classes whose occurence can be considered as balanced, this option is set to \textit{false}. 

\subsubsection{Training Initialization}

\noindent The tarining is initiated by entering these commands:

\begin{lstlisting}[language=bash]
# Navigate to the caffe-segnet folder
$ cd /SegNet/caffe-segnet/build/tools/
# Initiate training from scratch
$ ./caffe train -solver /SegNet/Models/segnet_solver.prototxt
# Resume training from a solver checkpoint (snapshot)
$ ./caffe train -solver /path/to/solver.prototxt -snapshot /path/to/snapshot_iter_XY.solverstate
\end{lstlisting}

The encoder and decoder weights are all initialized using MSRA method by default. Another scenario is when it's desired to use transfer learning. In this case, Caffe needs a path to the weight file of the pre-trained network. The corresponding command would be

\begin{lstlisting}[language=bash]
$ ./caffe train -solver /path/to/solver.prototxt -weights /path/to/pre_trained_weights.caffemodel
\end{lstlisting}

 [https://arxiv.org/pdf/1411.4734.pdf]
 
\subsection{Testing}

\subsection{Inference}

In this phase, the network is ready to be deployed. From this point, it's very convenient to use the CPW for running the network, feeding it with input data and calculating the segmentation accuracy. To run the final segmentation, some preparation steps must be taken first.

\subsubsection{Calculating Batch Statistics}
The Batch Normalisation layers [3] in SegNet shift the input feature maps according to their mean and variance statistics for each mini batch during training. At inference time we must use the statistics for the entire dataset and obtain the final weights for the inference phase. We do this by calling the \textit{compute\_bn\_statistics.py} which is meant to be run from the command line and needs to get command-line parameters. In PyCharm, we need to switch to Virtual Environment (venv) by opening Terminal and call:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 original_compute_bn_statistics.py /path/to/train.prototxt /path/to/snap_iter_XY.caffemodel /path/to/inference_folder
\end{lstlisting}

The script automatically edits the TRAIN file and turns it into a new INFERENCE file by removing the layers that are no longer needed. It also takes the weights specified in \textit{snap\_iter\_XY.caffemodel}, calculates the final weights and saves them to \textit{final\_weights.caffemodel}. Both the INFERENCE and weigh files are stored in the specified \textit{inference\_folder}.

The network architecture is now in the INFERENCE file and is the same as in the TRAIN file, apart from the input and output layers. The snippet below shows how the output changes: the loss function is no longer computed, the only output we care about are the Softmax probabilities. The DenseImageData layer is also skipped, because the data will be provided via CPW. 

\begin{lstlisting}
// Inference, input layer
name: "segnet_inference"
input: "data"
input_dim: 1	# Always 1 for SegNet
input_dim: 3
input_dim: 360
input_dim: 480
\end{lstlisting}

\subsubsection{Running the Segmentation}

For running the segmentation, we use the script \textit{segnet\_inference.py}. We must provide the network with images either by specifying a path to a video file, or by specifying a sequence of image names to follow in a folder (this is a standard OpenCV [odkaz na to jakej to ma mit format] convention). Once we have an appropriate test set of images, we run the segmentation by calling:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 segnet_inference.py /path/to/inference.prototxt /path/to/final_weights.caffemodel /path/to/videofile.avi 
\end{lstlisting}

\subsubsection{Evaluating Segmentation Performance}

The performance of semantic segmentation is often described by so called IoU (intercestion over union) metrics. IoU is the area of overlap between the predicted segmentation and the ground truth divided by the area of union between the predicted segmentation and the ground truth, as shown in Figure XY. This metric ranges from 0–1 (0–100\%) with 0 signifying no overlap and 1 signifying perfectly overlapping segmentation.

[https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2]

[https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/]

http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html

https://github.com/alexgkendall/caffe-segnet/issues/21