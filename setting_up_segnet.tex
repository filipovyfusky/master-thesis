\section{Image Annotation}

In supervised learning, one needs to manually create the training data consisting of inputs and corresponding targets (in segmentation, ground truths). There's a variety of annotation tools available on the internet, both under commercial and free licenses. 

\subsubsection{Labelbox}

Labelbox in a paid online annotation tool. The best feature of Labelbox is that it allows sharing the datasets with other users and therefore speed up the labeling significantly. Labelbox offers free access to the full version to students. When the labeling is finished, one needs to export the image/label pairs to a .JSON file. This file contains links to the annotated images that are stored online and it's necessary to download them separately (Labelbox is still in development, this is valid by the time of publishing the thesis). To automate this process, one can call the function \textit{download()} from the \textit{utilities.py} file (Attachment XY). 

%\section{Caffe Commands}

%The documentation for Caffe is not one of the best and sometimes it might be quite %tricky to find reasonable answers. Therefore, this section will give a brief %summary of the most important terms and parameters in Caffe library.

\section{Setting up SegNet}

Caffe implementation of a neural network typically consists of four \textit{.prototxt} files: \textit{train.prototxt}, \textit{solver.prototxt}, \textit{test.prototxt} and \textit{inference.prototxt}. The train, test and inference files are almost identical except for a few differences in the very first/last layers. The train file is used together with the solver file to train the network: the network architecture is determined by the train file and the parameters for optimization reside in the solver file. The test file is used by Caffe when one needs to test the network periodically during training on a validation dataset.  

The network files used in this section are available at [filip github].

\subsection{Solver Settings}

The solver file contains the optimization parameters. The detailed description of the parameters can be found in the original Caffe documentation on GitHub [odkaz na dokumentaci]. The description of the parameters used can be found in the snippet below. 

\begin{lstlisting}
// Training file
net: "/path/to/train.prototxt"	
// Caffe GPU version
solver_mode: GPU
// Solver type		
type: "AdaDelta"
// Initial learning rate, changes according to lr_policy		
base_lr: 0.061		
// Determines how the learning rate changes during training
lr_policy: "fixed"	
// Show loss and accuracy every 'display' iterations
display: 130
// Max number of iteration. One iteration = a pass of one mini-batch			
max_iter: 3000	
// Regularization technique called Weight decay		
weight_decay: 0.0005
// Saves the weights after 'snapshot' iterations
snapshot: 1000000		
snapshot_prefix: "/path/to/snap" 

// Testing parameters
test_initialization: false	
test_iter: 1
test_interval: 100000000
\end{lstlisting}

\subsection{Training}

\subsubsection{Input Layer and Input pre-processing}

The train file begins with the DenseImageData. Images and labels are loaded as \textit{.jpg} and \textit{.png} files directly from the hard drive (there are more methods Caffe offers). The path to the \textit{image\_paths.txt} file containg the image/label paths is entered as the \textit{source} parameter of the \textit{DenseImageData}. This layer also specifies the size of the mini batch. The value is limited by the amount of memory GPU offers. When a larger size of the mini batch is needed, one solution Caffe offers is to specify the \textit{iter\_size} parameter in the Solver file. The total mini batch size in Caffe is always a result of $iter\_size \cdot batch\_size$. By default, the value of \textit{iter\_size} is set to 1.

The \textit{shuffle} parameter in the DenseImageData layer determines whether the training dataset is shuffled after each epoch. This is usually desirable as it helps the optimization algorithm by bringing another stochasticity into the computation. The \textit{mirror} parameter applies random mirrors to the input data and hence augments the dataset. If one needs to apply more complex data augmentation techniques, it's necessary to perform them separately and feed the DenseImageData layer with already processed images.

\begin{lstlisting}
// The first layer in the network
name: "bayesian_segnet_train"
layer {
name: "data"
type: "DenseImageData"
top: "data"
top: "label"
dense_image_data_param {
	source: "/SegNet_navganti/data/custom/train_linux.txt"
	batch_size: 4   			    			
	shuffle: true
	mirror: true	
	}
# Per-channel mean
transform_param {
	mean_value: 129		#B component
	mean_value: 126		#G
	mean_value: 126		#R
	}
}
\end{lstlisting} 

The training images and their ground truths are stored as \textit{.jpg} and \textit{.png} files. The corresponding pairs are denoted as rows in the \textit{image\_paths.txt} file in the format 

$$
\text{\textit{/path/to/image.jpg /path/to/label.png}}
$$

This file is generated using the function \textit{make\_txt()} from \textit{utilities.py}. The script will also make separate directories for training, testing and validation datasets by calling \textit{make\_dirs()}.

The method used for mean subtraction was the per-channel mean method. The function per\_channel\_mean in utilities.py calculates the mean values for R, G and B components from the training set. These three numbers are then placed into the DenseImageData layer in BGR order (see Snippet XY).

\subsubsection{Output Dimensions}

In the original version, SegNet segments 11 classes. This corresponds to the pixel values in the .png label files starting from zero: for instance, segmentation mask for class number 1 has a pixel value 0 in the label file, etc. However, the goal of this thesis is to set the network to segment only two classes - \textit{path, background}. To change the size of the output classifier, it is necessary to change the output dimension of the last layer:

\begin{lstlisting}

// The last conv layer in the network
layer {
	bottom: "conv1_2_D"
	top: "conv1_1_D"
	name: "conv1_1_D"
	type: "Convolution"
	.
	.
	.
	convolution_param {
		.
		.
		.
		num_output: 2		// Set this to the number of classes
		pad: 1
		kernel_size: 3
	}
}
\end{lstlisting}

\subsubsection{Softmax Classifier}

When there is large variation in the number of pixels in each class in the training set (e.g road, sky and building pixels dominate the dataset) then there is a need to weight the loss differently based on the true class. This is called class balancing. The authors of SegNet use median frequency balancing [odkaz] where the weight assigned to a class in the loss function is the ratio of the median of class frequencies computed on the entire training set divided by the class frequency. This implies that larger classes in the training set have a weight smaller than 1 and the weights of the smallest classes are the highest. When no re-weighting is applied, we talk about natural frequency balancing. [doslovna citace??? segnet paper]

\begin{lstlisting}
// The Softmax classifier with cross-entropy loss
layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "loss"
	softmax_param {engine: CAFFE}
	loss_param: {
		weight_by_label_freqs: false	     
	}
}
// The last layer of the network
layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "conv1_1_D"
	bottom: "label"
	top: "accuracy"
	top: "per_class_accuracy"
}
\end{lstlisting}

%% Snippet XY, the last two layers of the train network

SegNet uses the cross-entropy loss as the loss function for training the network. In Caffe, median frequency balancing is available via the 'weight\_by\_label\_freqs' parameter in the \textit{SoftmaxWithLoss} layer. Since the dataset used has only two classes whose occurence can be considered as balanced, this option is set to \textit{false}. 

\subsubsection{Training Initialization}

\noindent The training is initiated by entering these commands:

\begin{lstlisting}[language=bash]
# Navigate to the caffe-segnet folder
$ cd /path/to/caffe-segnet/build/tools/
# Initiate training from scratch or
$ ./caffe train -solver /path/to/segnet_solver.prototxt
# or resume training from a solver checkpoint (snapshot)
$ ./caffe train -solver /path/to/segnet_solver.prototxt -snapshot /path/to/snapshot_iter_XY.solverstate
\end{lstlisting}

The encoder and decoder weights are all initialized using MSRA method by default. Another scenario is when it's desired to use transfer learning. In this case, Caffe needs a path to the weight file of the pre-trained network. The corresponding command would be

\begin{lstlisting}[language=bash]
$ ./caffe train -solver /path/to/solver.prototxt -weights /path/to/pre_trained_weights.caffemodel
\end{lstlisting}

 [https://arxiv.org/pdf/1411.4734.pdf]

\subsection{Inference}

In this phase, the network is ready to be deployed. From this point, it's very convenient to use the CPW for running the network, feeding it with input data and calculating the segmentation accuracy. To run the final segmentation, some preparation steps must be taken first.

\subsubsection{Calculating Statistics for Batch Normalisation}
The Batch Normalisation layers [3] in SegNet shift the input feature maps according to their mean and variance statistics for each mini batch during training. At inference time we must use the statistics for the entire dataset and obtain the final weights for the inference phase. We do this by calling the \textit{compute\_bn\_statistics.py} which is meant to be run from the command line and needs to get command-line parameters. In PyCharm, we need to switch to Virtual Environment (venv) by opening Terminal and call:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 original_compute_bn_statistics.py /path/to/train.prototxt /path/to/snap_iter_XY.caffemodel /path/to/inference_folder
\end{lstlisting}

The script automatically edits the TRAIN file and turns it into a new INFERENCE file by removing the layers that are no longer needed. The network architecture is now in the INFERENCE file and is the same as in the TRAIN file, apart from the input and output layers. The snippet below shows how the output changes: the loss function is no longer computed, the only output we care about are the Softmax probabilities. The DenseImageData layer is also skipped, because the data will be provided via CPW. part of this is switching all batch normalisation layers to the INFERENCE mode.

The script takes the desired .caffemodel file specified in \textit{snap\_iter\_XY.caffemodel}, calculates new $ /gamma, /beta $ parameters for the batch normalisation layers and saves everything to \textit{final\_weights.caffemodel}. Both the INFERENCE and weigh files are stored in the specified \textit{inference\_folder}.

\begin{lstlisting}
// Inference, input layer
name: "segnet_inference"
input: "data"
input_dim: 1	# Always 1 for SegNet
input_dim: 3
input_dim: 360
input_dim: 480
\end{lstlisting}

\subsubsection{Running the Segmentation}

For running the segmentation, we use the script \textit{segnet\_inference.py}. We must provide the network with images either by specifying a path to a video file, or by specifying a sequence of image names to follow in a folder (this is a standard OpenCV [odkaz na to jakej to ma mit format] convention). Once we have an appropriate test set of images, we run the segmentation by calling:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 segnet_inference.py /path/to/inference.prototxt /path/to/final_weights.caffemodel /path/to/videofile.avi 
\end{lstlisting}

\subsection{Testing}

The TEST file is used only for calculating the loss on the validation dataset. It needs to be created from the INFERENCE file by manually putting back the input and output layers from the TRAIN file: DenseImageData layer with specified path to the validation dataset as the input and SoftmaxWithLoss followed by Accuracy layers as the output. However, there's still need to use the new net parameters computed by \textit{compute\_bn\_statistics.py} to ensure proper function of the batch normalisation layers, which still remain in the INFERENCE mode and hence differ from the TRAIN file.

Testing is executed similarly as training using the command line:

\begin{lstlisting}[language=bash]
# Navigate to the caffe-segnet folder
$ cd /path/to/caffe-segnet/build/tools/
# Initiate testing
$ ./caffe train -model /path/to/segnet_test.prototxt -weights /path/to/final_weights.caffemodel
\end{lstlisting}

\subsubsection{Evaluating Segmentation Performance}

The performance of semantic segmentation is often described by so called IoU (intercestion over union) metrics. IoU is the area of overlap between the predicted segmentation and the ground truth divided by the area of union between the predicted segmentation and the ground truth, as shown in Figure XY. This metric ranges from 0–1 (0–100\%) with 0 signifying no overlap and 1 signifying perfectly overlapping segmentation.

[https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2]

[https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/]

http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html

https://github.com/alexgkendall/caffe-segnet/issues/21

\subsection{Bayesian SegNet}

Since Bayesian SegNet differs from SegNet only in terms of added dropout layers and slightly different method of performing network inference, the above-mentioned procedures for setting the solver and training are applicable in the same way. One can therefore start the training by using the commands from the previous section and only replace the file paths of the TRAIN and SOLVER files. The TEST and INFERENCE files have only one major difference in the input layers. 

Unlike in SegNet, the \textit{batch\_size} parameter in the DenseImageData layer of the TEST file now represents the number of Monte Carlo Dropout samples used for output averaging, as described in Section XY. The same corresponds to the first dimension of the input layer in the INFERENCE file.

After calling the script \textit{compute\_bn\_statistics.py} on a trained Bayesian SegNet, we can start the inference by executing:

\begin{lstlisting}[language=bash]
(venv) user@user:/path/to/Scripts$ python3 bayesian_segnet_inference.py /path/to/inference.prototxt /path/to/final_weights.caffemodel /path/to/videofile.avi 
\end{lstlisting}

Here the scripts also visualizes the statistics of Monte Carlo sampling: the uncertainty and variance of the output segmentation.

\subsection{SegNet Basic and Bayesian SegNet Basic}

These shallow versions of SegNet and BayesianSegNet are used in the same way as their full versions above. The same procedures apply to SegNet/SegNet Basic and Bayesian SegNet/Bayesian SegNet Basic.

\section{Training Hyperparameters}

The choice of hyperparameters is a task for itself and requires a sufficient amount of tries and errors. There are some general recipes (all of them are empirical) for finding the right parameters one can follow. 

\subsubsection{Optimizer}

Every training of a neural network starts with the choice of optimizer. As the most recent research suggest, Adam is the default choice for training CNN. [zdroj] 

\subsubsection{Learning Rate}

The parameter that has the biggest effect on training is the learning rate. This is the first parameter to begin with. It's recommended to start a coarse search first, observe the training loss for both training and validation datasets for a few initial epochs and then choose the optimal learning rate value and perform finer search. 

As the learning rate has a multiplicative effect on the gradient accumulation during mini-batch training, it's logical to pick the values from logarithmic space. 

\subsubsection{Regularisation}

When building a network from scratch, one starts with a simple SGD algorithm with no reguilarisation involved to ensure that the loss values are reasonable. Once it is ensured that there are no errors in the code and the network trains with SGD, regularisation is turned on. [STANFORD L6] Then it's usually set to a very small value, typically of the order $ 10^{-4} $ [zdroj].
\\
\subsubsection{Cross-validation Strategy}

This strategy is also referred to as early stopping. The idea is that one observes both training and validation loss during training. When these losses go apart, the network tends to overfit to the training data. This is a crucial step when finding optimal hyperparameters and always needs to be checked.


