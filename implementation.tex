\chapter{Implementation and method}

In this chapter, the original Caffe [] implementation of SegNet and Bayesian SegNet together with their simplified version SegNet Basic and Bayesian SegNet Basic will be tested on a custom dataset. Part of this will be evaluating the effect of various training hyperparameters, solvers, data augmentation techniques etc. This will also give the instructions on how to set up the software/hardware environment to run Caffe framework.

The Caffe code used in this section is available at [filip github].

\section{CPU vs. GPU for Training ANN}

CPU is the main processing unit of a computer. Current CPU's usually have 4 to 8 separate cores, which allows them to run several tasks in parallel. Graphics processing unit (GPU) was originally designed for performing only rendering computer graphics. Table XY gives and idea of how these two computational units differ in terms of the kind of task they're designed for. Note that CPU has much lower number of cores, but these run at high frequency and are very capable in terms of the instructions they perform. Therefore, CPU's are great for sequential tasks. On the other hand, GPU comprises of a large number of 'simple' cores, which makes it better for computing parallel tasks. 

In terms of the available memory, CPU doesn't have its own resources (apart from the very small memory sections called caches) and has access to the system's RAM, whose size is very often between 8 and 32 GB for powerful PC's. GPU's, on the other hand, have their own block of RAM on the chip because the access top the main system's RAM has usually many bottlenecks. The size of the RAM for the top-end GPU's ranges from 8 to 12 GB.

The main part of the computations in Neural Networks in general is matrix multiplication. For this, GPU has the power of performing these operations by parts in parallel which speeds up the training significantly. 

There have been created abstraction frameworks such as CUDA and OpenCL, that allow programmers do write their code in an usual manner and run it directly on GPU. For the purposes of Neral Networks, NVIDIA has developed a library of the most commonly used CUDA primitives named cuDNN. 

\subsubsection{Tensor Cores}

Tensor Core is a special GPU feature offered by NVIDIA cards. It enables mixed-precision computing, dynamically adapting calculations to accelerate throughput while preserving accuracy. The latest generation expands these speedups to a full range of workloads. From 10x speedups in AI training with Tensor Float 32 data type, to 2.5x boosts for high-performance computing with floating point 64 (double precision). [nvidia site]

\section{ANN frameworks}

As the architecture and training of Neural Networks are getting more complicated, there is a room for programmers to make ANN frameworks such as Caffe, TensorFlow, and PyTorch as user friendly as possible. The idea of these software tools is to make a higher abstraction of the architecture of the network called computational graph. The user can therefore think of designing and training the network separately by applying an optimizer to the computational graph that represents the layers of the network. 

Caffe is a deep learning framework made with expression, speed, and modularity in mind. It is developed by Berkeley AI Research (BAIR) and by community contributors. [berkeley caffe] The main difference from the other mentioned frameworks is that the user often doesn't need to write any code at all. The architecture of the network (the computational graph) is created in a .prototxt file, which is a standard text file in which one fills in the subsequent layers of the network in the desired order. Also, rather than having a optimizer object, one creates another .prototxt file that contains parameters such as the optimizer type (SGD, Adam, etc.), learning rate, momentum constant and others. After both of this files are created, the user runs Caffe computation from the command line. The core of the framework is written in C++. Pre-built binaries are called When the computation is started.

Caffe also has bindings for Python (CPW - Caffe Python Wrapper) and Matlab, which if very useful for evaluating the training statistics. The biggest downside of Caffe and CPW is that they are very poorly documented.

\section{Setting up Environment for Caffe}

\subsection{Hardware configuration}

The GPU used for the computations has been picked according to the most up-to-date benchmarks and recommendations found online [source]. When choosing GPUs in general, one needs to decide between ATI/AMD and NVIDIA chips. For this case however, NVIDIA is the choice because it's way more 'ANN-friendly' as it's offering more features specifically designed for ANN computations. 

It is also advisable to use SSD in the PC configuration, because the data flow begins from reading the training data (images) from a storage, in this case from the computer's hard drive. Another way is moving the training data into RAM before the training is initiated [source, dalasi info]. 

Table XY shows the complete PC specifications used for training SegNet for the purposes of this thesis.  

\subsection{Software configuration} 

\subsubsection{Operating System} 

The standard platform for running Caffe is Ubuntu, which is a Linux distribution from Cannonical based on Debian. The environment used is Ubuntu 18.04 LTS 64 bit. Is is important to let the Ubuntu installer download the latest updates, or, after the installation, invoke the update command to ensure that the most up-to-date packages will be installed. For this, one can call

\begin{lstlisting}[language=bash]
$ sudo apt update
$ sudo apt upgrade
\end{lstlisting}

\subsubsection{Enabling NVIDIA driver}

Ubuntu 18.04 enables the default Nouveau graphics driver after installation. Before taking other steps, it is vital to disable the Nouveau driver and use NVIDIA instead in \textit{Application menu -> Software \& Updates -> Additional drivers
	-> Using NVIDIA driver metapackage from nvidia-driver-XYZ (proprietary, tested) -> Apply changes.} The driver version used is nvidia-driver-440.

[https://www.linuxbabe.com/ubuntu/install-nvidia-driver-ubuntu-18-04]

\subsubsection{CUDA installation}

CUDA version is determined by the version of cuDNN compatible with the used Caffe version, which is cuDNN 5.1 in this case. The corresponding CUDA version is CUDA 8.0. On Ubuntu 18.04, the procedure is the following:

\begin{itemize}
	\item \textbf{Download CUDA 8.0 runfile.} Go to \href{https://developer.nvidia.com/cuda-80-ga2-download-archive}{CUDA Legacy Releases} and look for 'CUDA Toolkit 8.0 GA2 (Feb 2017)'. The standard .deb installer support only Ubuntu 16.04 LTS and therefore the installation must be performed via the runfile method. Navigate to Linux -> x86\_64 -> Ubuntu -> 16.04 -> runfile (local) -> Base installer. Also, download the Patch file. 
	
	\item \textbf{Perform the runfile installation of CUDA.} Open the Ubuntu Terminal (Ctrl+Alt+T) and run
	
	\begin{lstlisting}[language=bash]
	$ cd /path/to/cuda_8.0.61_375.26_linux.run # Navigates to folder with CUDA
	$ sudo chmod a+x cuda*		# Makes the cuda*.run executable
	$ ./cuda*.run --tar mxvf 	# Unpacks the .runfile content
	$ sudo cp InstallUtils.pm /usr/lib/x86_64-linux-gnu/perl-base  # Copy one of the extracted files to perl-base
	$ sudo sh cuda_8.0.61_375.26_linux.run --override # Start the installation 
		# The licence agreement
		$ accept 
		# You are attempting to install on an unsupported configuration. Do you wish to continue?
		$ yes 
		# Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 375.26?
		$ no
		# Install the CUDA 8.0 Toolkit?
		$ yes 
		$ <press enter> (leave deafult location)
		# Do you want to install a symbolic link at /usr/local/cuda?
		$ yes
		# Install the CUDA 8.0 Samples?
		$ no
	\end{lstlisting}
	
	After the installation is done, ignore the '***WARNING: Incomplete installation!' statement, because the NVIDIA driver is already installed. 
	
	Now run the CUDA 8.0 Patch 2 installation is a similar fashion:
	
	\begin{lstlisting}[language=bash]
	$ sudo sh cuda_8.0.61.2_linux.run
	\end{lstlisting}
	
	\item \textbf{Perform the post-installation actions.} The system needs to know the location of CUDA executables. The common way is to set these "PATH" variables in the current session of the Terminal. However, it's useful to add these permanently to '\textasciitilde{}/.bashrc' :
		
	\begin{lstlisting}[language=bash]
	$ sudo gedit ~/.bashrc # Opens the .bashrc file in text editor
	\end{lstlisting}
	
	In the text editor, append the following two statements to the end of the file:
	
	\begin{lstlisting}[language=bash]
	export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}
	export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64\
			${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
	\end{lstlisting}	
	
	From this point, all newly opened Terminal sessions should have the paths set correctly. 
	
\end{itemize}

\subsubsection{cuDNN installation}

The NVIDIA CUDA Deep Neural Network library (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. It provides highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers. [https://developer.nvidia.com/cudnn] 

\begin{itemize}
	\item \textbf{Download cuDNN 5.1 for CUDA 8.0.} To get the appropriate cuDNN version for Caffe and CUDA 8.0, go to \href{https://developer.nvidia.com/rdp/cudnn-archive}{cuDNN Archive} (requires login) and look for \textit{Download cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0 -> cuDNN v5.1 Library for Linux}. Extract the archive, navigate to the extracted folder and copy the files to the CUDA 8.0 installation folder:
	
	\begin{lstlisting}[language=bash]
	$ tar -xf cudnn-8.0-linux-x64-v5.1.tgz 
	$ cd cuda
	$ sudo cp -a include/cudnn.h /usr/local/cuda/include/
	$ sudo cp -a lib64/libcudnn* /usr/local/cuda/lib64/
	\end{lstlisting}	
\end{itemize}

\subsubsection{Setting up Python Editor}

The scripts for evaluating SegNet performace are written in Python. It's advisable to use Pycharm Community Edition for an editor, because it offers a very convenient combination of GUI and the standard command line environment.

A good practice is to use Python virtual environment to easily maintain the required packages and to make the project transferable to another Linux PC. In Pycharm, we can do this in an active Pycharm project by going to \textit{File -> Settings -> Project -> Project Interpreter -> <wheel icon on the right> -> Add}. The standard choice is the Virtualenv Environment. The Base interpreter location on a fresh Ubuntu installation is '/usr/bin/python3.6'. When we click OK, Pycharm creates a 'venv' folder at the specified location including all package files we install.

When the virtualenv is configured properly, is will automatically be activated when we enter the Linux Terminal session by clicking on 'Terminal' located at the bottom bar of Pycharm. From this Terminal, we'll be launching all SegNet scripts and use it to install the required packages by calling 'pip3 install <package-name>'.

\subsection{Building Caffe for SegNet} 

The Caffe code is an open-source software. The authors of the SegNet created a slightly modified version of Caffe (caffe-segnet) that supports special SegNet layer types (upsample, bn, dense\_image\_data and softmax\_with\_loss (with class weighting)).

In addition, since the original caffe-segnet supports just cuDNN v2, which is not supported for new pascal based GPUs, there's another version of caffe-segnet from [TimmoSaemannGithub] that supports cuDNN 5.1 and decreases the inference time by 25 \% to 35 \%. This version has therefore been selected for running SegNet. From this point on, the term 'Caffe' will be equivalent to 'caffe-segnet' in the text.

\begin{itemize}
		
	\item \textbf{Install Caffe dependencies.} Caffe is available as a source code and therefore needs to be compiled on the target platform. For this, several steps need to be taken to ensure that all libraries are available during the build. 
	
	\begin{lstlisting}[language=bash]
	$ sudo apt install python3-opencv 			# OpenCV, version 3
	$ sudo apt-get install libatlas-base-dev 	# Atlas BLAS library
	$ sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler
	$ sudo apt-get install libboost-all-dev		# Boost
	$ sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev
	$ sudo apt-get install python3-pip
	$ sudo pip3 install protobuf
	$ sudo apt-get install the python3-dev
	\end{lstlisting}
	
	\item \textbf{Download Caffe (caffe-segnet-cudnn5) source code.} Go to \href{https://github.com/TimoSaemann/caffe-segnet-cudnn5}{Timmoe Saemann's Github repository} and clone/download it. 
	\item \textbf{Set the build configuration file.} The build is done via the 'make' command, which needs the 'Makefile.config' file to be present in the parent directory ('caffe-segnet-cudnn5-master'). This file contains the build options and needs to be configured properly. Fortunately, the correct form of 'Makefile.config' is part of this thesis and can be found in the Attachment XY. 
	
	\item \textbf{Install gcc/g++ compliers.} The CUDA/cuDNN libraries used during the build are compatible only with gcc/g++ compilers of version 5. To install these, run:
	
	\begin{lstlisting}[language=bash]
	$ sudo apt install gcc-5 g++-5
	# Create symbolic links so CUDA can see the proper compiler binaries
	$ sudo ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc
	$ sudo ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++
	\end{lstlisting}
	
	\item \textbf{Start the build.} Once the 'Makefile.config' file is located in the 'caffe-segnet-cudnn5-master', everything should be ready for the final step. Type these commands to initiate and test the Caffe build (don't forget to build pycaffe (Caffe Python Wrapper)):
	
	\begin{lstlisting}[language=bash]
	make all -j4	# start build
	make test -j4	# test build
	make runtest	# run Caffe and test it
	make pycaffe	# build pycaffe 
	\end{lstlisting} 	
\end{itemize}
[https://mc.ai/installing-caffe-on-ubuntu-18-04-with-cuda-and-cudnn/]