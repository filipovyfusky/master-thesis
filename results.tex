\chapter{Results}

The segmentation networks introduced in the previous chapter, SegNet, Bayesian SegNet and their simpler versions (Basic) were trained using the described techniques and various hyperparameters. The solver used for optimization was AdaDelta in all cases.
The default choice for CNN is usually Adam, but its implementation in Caffe takes much more memory than other algorithms. That is why the algorithm chosen for training is AdaDelta, which is used by many SegNet users [github implementace segnetu v tensorflow].

As AdaDelta adapts the learning rate over the course of training, there's no longer a need to manually tune the learning rate decay scheme (which would be another hyperparameter). Therefore, the first hyperparameter to tune was the base learning rate. The search was initiated within a coarse interval of values: $ <10^{-3}, 10^{0}>  $. This interval was divided into three sub-regions to make the random choice more balanced. Then, the values within each interval were selected using Uniform random distribution. The training loss was observed for five epochs. Since the Caffe implementation of SegNet comes with custom scripts for calculating batch-normalisation statistics for inference, checking the validation loss periodically becomes extremely memory demanding and time inefficient. Therefore, the validation loss was computed only once at the end of the last training epoch to ensure that the values of losses had not diverged.  

When a reasonable learning rate value range was found, the random search was limited to this interval and the training was executed until no further change in the loss function was observed. 

In the original paper, authors use L2 regularization. This values stayed unchanged and remained the same as the SegNet authors suggest.  

This scheme was applied to all SegNet variants. The difference observed is the time it takes to achieve low loss values. This is influenced by the size of the network (Basic versions train faster) and the dropout settings (dropout slows down the training). 

%https://stackoverflow.com/questions/50853538/caffe-why-dropout-layer-exists-also-in-deploy-testing

Hyperparameters are, unlike the free parameters, parameters that have to be set before the training
starts and are not affected by the training.

Training Set
Mostly taken about 60% of the original dataset, the training set is used to generate
the prediction algorithm. The algorithm tunes and tweaks the weights according to
this data. The generated model is tested with different algorithms to compare the
performances during the cross-validation phase.
15CHAPTER 3. THEORY
Validation Set
The validation set, sometimes known as the cross-validation set, is about 20% of
the original data set. The algorithms are tested with each other to be able to select
the best performing algorithm. A simultaneous training and validation can help in
improving the results with every training loop.
Test Set
The test data should be taken as high as possible to comprehend the performance
of the prediction algorithm on an unseen data on which it has not been trained on.
Better performance on the untrained data will reflect whether or not the network
will perform well at real-world unknown scenarios.
--------------TRAINING CAFFE NOTES---------------

We train the model with dropout and sample the posterior distribution over the weights at test time using dropout
to obtain the posterior distribution of softmax class probabilities. We take the mean of these samples for our segmentation prediction and use the variance to output model uncertainty for each class. We take the mean of the per class variance measurements as an overall measure of model uncertainty.