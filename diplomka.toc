\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}
\contentsline {chapter}{\numberline {2}Problem Statements}{4}{chapter.2}
\contentsline {chapter}{\numberline {3}Research and Theory}{5}{chapter.3}
\contentsline {section}{\numberline {3.1}Architecture of artificial neural networks}{5}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Feed-forward networks}{5}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}McCulloch-Pitts neurons}{6}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}Activation functions}{7}{subsection.3.1.3}
\contentsline {subsubsection}{Sigmoid}{8}{section*.10}
\contentsline {subsubsection}{Hyperbolic tangent}{9}{section*.12}
\contentsline {subsubsection}{Rectified linear unit (ReLU)}{9}{section*.14}
\contentsline {subsubsection}{Leaky ReLU}{10}{section*.16}
\contentsline {subsection}{\numberline {3.1.4}Multilayer perceptrons}{11}{subsection.3.1.4}
\contentsline {subsubsection}{Output classifier - softmax}{12}{section*.19}
\contentsline {subsubsection}{Linear separability}{12}{section*.21}
\contentsline {section}{\numberline {3.2}Training of artificial neural networks}{14}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Loss function}{14}{subsection.3.2.1}
\contentsline {subsubsection}{Mean squared error (MSE)}{14}{section*.23}
\contentsline {subsubsection}{Negative log likelihood}{14}{section*.24}
\contentsline {subsubsection}{Cross entropy loss}{14}{section*.25}
\contentsline {subsection}{\numberline {3.2.2}Gradient optimization and backpropagation}{15}{subsection.3.2.2}
\contentsline {subsubsection}{Gradient descent}{15}{section*.27}
\contentsline {subsubsection}{Stochastic gradient descent}{17}{section*.29}
\contentsline {subsubsection}{Vanishing and exploding gradient problems}{17}{section*.30}
\contentsline {subsubsection}{Momentum}{18}{section*.31}
\contentsline {subsubsection}{Other optimization algorithms}{19}{section*.33}
\contentsline {subsection}{\numberline {3.2.3}Improving training performance}{20}{subsection.3.2.3}
\contentsline {subsubsection}{Initialization of weights and thresholds}{20}{section*.35}
\contentsline {subsubsection}{Overfitting and regularisation}{20}{section*.36}
\contentsline {subsubsection}{Batch normalisation}{21}{section*.37}
\contentsline {subsubsection}{Dropout}{21}{section*.38}
\contentsline {subsubsection}{Data augmentation}{21}{section*.40}
\contentsline {subsubsection}{Early stopping}{21}{section*.41}
\contentsline {subsubsection}{Transfer learning}{22}{section*.43}
\contentsline {subsubsection}{Data pre-processing}{22}{section*.44}
\contentsline {section}{\numberline {3.3}Convolutional neural networks}{23}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}CNN layer types}{23}{subsection.3.3.1}
\contentsline {subsubsection}{Convolution layers}{23}{section*.45}
\contentsline {subsubsection}{Pooling layers}{24}{section*.47}
\contentsline {subsubsection}{Fully connected layers (FCN)}{24}{section*.49}
\contentsline {subsection}{\numberline {3.3.2}Examples of CNN architectures}{25}{subsection.3.3.2}
\contentsline {section}{\numberline {3.4}Semantic segmentation}{26}{section.3.4}
\contentsline {subsection}{\numberline {3.4.1}Encoder-decoder architecture}{26}{subsection.3.4.1}
\contentsline {subsubsection}{Input upsampling}{27}{section*.52}
\contentsline {subsection}{\numberline {3.4.2}SegNet}{28}{subsection.3.4.2}
\contentsline {subsubsection}{SegNet - encoder}{28}{section*.55}
\contentsline {subsubsection}{SegNet - decoder}{28}{section*.56}
\contentsline {subsection}{\numberline {3.4.3}Bayesian SegNet}{29}{subsection.3.4.3}
\contentsline {subsubsection}{Monte Carlo Dropout}{29}{section*.57}
\contentsline {subsection}{\numberline {3.4.4}Evaluating segmentation performance}{29}{subsection.3.4.4}
\contentsline {chapter}{\numberline {4}Implementation and Method}{30}{chapter.4}
\contentsline {section}{\numberline {4.1}CPU vs. GPU for training ANN}{30}{section.4.1}
\contentsline {subsubsection}{Tensor cores}{30}{section*.59}
\contentsline {section}{\numberline {4.2}Libraries for ANN}{31}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Caffe}{31}{subsection.4.2.1}
\contentsline {section}{\numberline {4.3}Setting up environment for Caffe}{32}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}Hardware configuration}{32}{subsection.4.3.1}
\contentsline {subsection}{\numberline {4.3.2}Software configuration}{33}{subsection.4.3.2}
\contentsline {subsubsection}{Operating system}{33}{section*.62}
\contentsline {subsubsection}{Enabling NVIDIA driver}{33}{section*.63}
\contentsline {subsubsection}{CUDA installation}{33}{section*.64}
\contentsline {subsubsection}{Installation of cuDNN}{34}{section*.65}
\contentsline {subsubsection}{Setting up Python editor}{35}{section*.66}
\contentsline {subsection}{\numberline {4.3.3}Building Caffe for SegNet}{35}{subsection.4.3.3}
\contentsline {section}{\numberline {4.4}Image annotation}{37}{section.4.4}
\contentsline {subsubsection}{Labelbox}{37}{section*.67}
\contentsline {section}{\numberline {4.5}Setting up SegNet}{38}{section.4.5}
\contentsline {subsection}{\numberline {4.5.1}Solver settings}{38}{subsection.4.5.1}
\contentsline {subsection}{\numberline {4.5.2}Training}{39}{subsection.4.5.2}
\contentsline {subsubsection}{Input layer and input pre-processing}{39}{section*.69}
\contentsline {subsubsection}{Output dimensions}{40}{section*.70}
\contentsline {subsubsection}{Softmax classifier}{41}{section*.71}
\contentsline {subsubsection}{Training initialization}{41}{section*.72}
\contentsline {subsection}{\numberline {4.5.3}Inference}{43}{subsection.4.5.3}
\contentsline {subsubsection}{Calculating statistics for batch normalisation}{43}{section*.73}
\contentsline {subsubsection}{Running the segmentation}{43}{section*.74}
\contentsline {subsection}{\numberline {4.5.4}Testing}{44}{subsection.4.5.4}
\contentsline {subsection}{\numberline {4.5.5}Bayesian SegNet}{45}{subsection.4.5.5}
\contentsline {subsection}{\numberline {4.5.6}SegNet Basic and Bayesian SegNet Basic}{46}{subsection.4.5.6}
\contentsline {section}{\numberline {4.6}Optimization of hyperparameters}{47}{section.4.6}
\contentsline {subsubsection}{Optimizer}{47}{section*.75}
\contentsline {subsubsection}{Learning rate}{47}{section*.76}
\contentsline {subsubsection}{Cross-validation strategy}{47}{section*.77}
\contentsline {subsubsection}{Regularisation}{47}{section*.78}
\contentsline {chapter}{\numberline {5}Results}{48}{chapter.5}
\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{52}{chapter.6}
\contentsline {chapter}{\numberline {7}Bibliography}{53}{chapter.7}
\contentsline {chapter}{List of Abbreviations}{57}{section*.83}
\contentsline {chapter}{List of Attachments}{58}{section*.84}
\contentsline {chapter}{List of Figures}{60}{section*.85}
\contentsline {chapter}{List of Tables}{61}{section*.86}
